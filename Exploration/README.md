# 일상대화 <b>D</b>ataset 만들기 과정

  

본 데이터는 일상 대화 데이터 셋을 만드는 과정을 리뷰하기 위해 만들어 졌다.
1. 일상대화 데이터 셋 분석
		1,일상대화,"이거 들어바 와 이 노래 진짜 좋다 그치 요즘 이 것만 들어 진짜 너무 좋다 내가 요즘 듣는 것도 들어봐 음 난 좀 별론데 좋을 줄 알았는데 아쉽네 내 취향은 아닌 듯 배고프다 밥이나 먹으러 가자 그래"
		2,일상대화,"야 박보영 오늘 학원 갔다왔어 아니 오늘 못갔어 왜 아니 친구랑 놀다가 시간을 못봤어 자랑이냐 깜빡했어 저녁은 뭐야 너는 저녁 없어 학원 다녀왔어야지 엄마 미안해 나 배고파 다음부터 꼭 가 알았어 나 손 씻고올게 깨끗하게 씻고와"
		3,일상대화,"오늘 너 미팅아니야 맞아 망했어 오늘 왜 뭐가 문제야 나 살이 너무 많이 쪘나봐 옷이 다 이상해 괜찮은데 뭐가 그래 어디서 만나냐 오늘 강남역에서 보기로했어 누구랑 그 너 친구 민영이랑 이대이야 맞아 나 괜찮지 이옷 응 이쁘네 재밌게 놀다와라 알았어 나 오늘 늦을수도 있다 먼저 자"
	1. 일상 대화는 위의 예문과 같이 index,class,conversation으로 이루어 져있다.
2. 알고리즘을 통한 일상대화 생성
	1. GPT 요청 프롬프트
		1. 위의 예문을 주어주고
		2. 같은 규칙을 따라서 대화 형식으로 일상대화 데이터를 만들어서 .csv 파일로 1000개의 문장을 만들어 줘
	2. 결과
		1. 위와 같이 5개의 예문을 주고 나머지는 자동으로 생성하는 코드를 만들어주었다. ![alt text](image.png)
		    2. 알고리즘을 통한 데이터 셋
			1,일상대화,"요즘 날씨 진짜 이상하지? 요즘 좀 피곤하네. 음, 좀 고민되네. 근데 그거 어디서 봤어? 알겠어, 고마워! 출근길 진짜 힘들다. 맞아, 나도 비슷해. 비 오면 또 달라지려나. 알겠어, 고마워! 주말에 뭐할 계획이야? 조용히 쉬었어. 대박이다. 생각보다 괜찮더라. 슬슬 쉬어야겠다. 출근길 진짜 힘들다. 시간이 너무 빨리 간다. 헉, 진짜? 사진 있으면 보내줘. 나중에 이야기 더 하자."
			2,일상대화,"운동 다녀왔어. 시간이 너무 빨리 간다. 맞아, 나도 비슷해. 비 오면 또 달라지려나. 오늘도 파이팅하자. 오늘 뭐 했어? 일이 조금 많았어. 아 그렇구나. 내일은 좀 쉬어야겠다. 좋은 하루 보내! 오늘 뭐 했어? 대박이다. 다음에 같이 가자. 좋은 하루 보내! 카페에서 공부 중이야. 아 그렇구나. 사진 있으면 보내줘. 내일 봐."
			3,일상대화,"오늘 뭐 했어? 아 그렇구나. 쿠폰 있으면 같이 쓰자. 오늘도 파이팅하자. 주말에 뭐할 계획이야? 시간이 너무 빨리 간다. 음, 좀 고민되네. 다음에 같이 가자. 내일 봐. 오늘 뭐 했어? 시간이 너무 빨리 간다. 헉, 진짜? 쿠폰 있으면 같이 쓰자. 나중에 이야기 더 하자. 점심 먹었어? 아 그렇구나. 사진 있으면 보내줘. 슬슬 쉬어야겠다. 어제 그 드라마 봤어? 생각보다 바빴어. 맞아, 나도 비슷해. 근데 그거 어디서 봤어? 슬슬 쉬어야겠다."
		3. 알고리즘 데이터 셋 분석
			1. 알고리즘을 이용해 약 1000개의 데이터를 만들었다.
			2. 알고리즘을 이용한 데이터 셋은 GPT를 통해 생성한 데이터와 다르게 하나의 대화에서 사진 있으면 보내줘. 슬슬 쉬어야겠다. 어제 그 드라마 봤어? 생각보다 바빴어. 와 같이 **문맥에 맞지 않는 동문 서답 하는 경우가 매우 많았다.**
			3. 또한 쿠폰 있으면 같이 쓰자.=446번, 시간이 너무 빨리 간다.=384번 같이 대부분이 같은 문장을 반복하는 형식이며 이에 따라서 일상대화가 특정 문장에 과적합될 우려가 있다.
				![alt text](<Pasted image 20250822165550.png>)
				문장중 '시간이 너무 빨리 간다.' 반복하는 결과
			 4. 이를 통한 학습을 반영한 결과 0.55점을 얻는 결과를 얻을 수 있었다.
 3. GPT를 통한 데이터 생성
	 1. 이전에 GPT를 통해 뽑은 5개의 샘플을 보았을 때 충분한 결과를 볼 수 있었다.
	 2. 그러나 한번에 많은 일상대화를 만들어 달라고 하는 경우 이전처럼 코드를 만들어 주고 직접 해결 하도록 유도하는 문제가 발생했다.
	 3. 때문에 1000, 500, 100, 50, 25개씩 일상대화를 만들어 달라고 요청해보면서 정상적으로 GPT가 일상대화를 만들어 주는 최소 개수를 확인 한 결과 25개를 요청하면 코드 반환 없이 일상 대화를 만들어 주는 것을 확인 했다.
	 4. 또한 다른 데이터와 혼동되지 않은 데이터를 만들기 위해 프롬프트를 작성했다.
			'일반 대화' 데이터 생성을 위한 프롬프트
			1. 핵심 목표: 내용 완전히 중립적이거나 긍정적인 '일반 대화' 데이터셋을 생성합니다.
			생성 수량: 총 25개
			2. 구조적 특성 (Structural Properties)
			화자 수: 모든 대화는 반드시 정확히 2명 (화자 A, 화자 B)으로 구성되어야 합니다.
			대화 턴(Turn) 수: 약간의 편차(예: 8~12턴)를 포함할 수는 있으나, 전체 평균은 10.3턴에 근접해야 합니다.
			3. 길이 특성 (Length Properties)
			전체 대화 길이: 하나의 대화는 평균 210~250 글자 범위 내외가 되어야 합니다. 분포는 긴 쪽으로 꼬리가 있는 형태(right-skewed)를 따릅니다.
			4. 내용 및 어휘 특성 (Content & Vocabulary Properties)
			대화 주제: 갈등이나 부정적인 내용이 아닌, 일상적이고 평범한 주제로 대화를 구성해야 합니다.
			주제: 날씨 이야기, 약속 잡기, 취미 공유 등.
			
			위와 같은 규칙을 따라서 대화 형식으로 일상대화 데이터를 만들어 줘
	5. 이러한 방식으로 주제를 바꿔 가면서 GPT를 통해 계속 25개씩 데이터를 생성
		1. 이러한 방식을 사용할 경우 동문서답이나 동일 문장의 반복의 문제를 해결 할 수 있었다.
	6. 동일 레파토리 반복 문제
		   1. 일상대화,"세계에서 제일 좋아하는 음식은? 
			  음, 스시! 
			  오, 왜? 응, 신선하고 맛있잖아. 
			  나도 스시 좋아하는데. 
			  우리 같이 스시 먹으러 갈래? 
			  좋아!" 
		2. 일상대화,"세계에서 제일 좋아하는 영화는? 
			   음, '센과 치히로의 행방불명'! 
			   오, 왜? 응, 뭔가 몽환적이고 신비로워. 
			   나도 '센과 치히로의 행방불명' 좋아하는데. 
			   우리 같이 '센과 치히로의 행방불명' 볼래? 
			   좋아!"
			25개의 일상 대화를 만드는 구간에서 동일한 레파토리를 반복한다.
	7. 여러 GPT 모델 사용
		1. 레파토리를 다양하게 하기 위해 다양한 GPT 모델을 통해 데이터를 확보하기로 했다.
		2. 이전과 같은 프롬프트를 이용해서 Gemini, Grok, DeepSeek 모델을 활용해 데이터를 생성 했다.
		

 